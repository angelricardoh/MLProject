{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 567 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotes:\\n- GarageType variable might be biased. Note that it has a 2types variable making our dummy variables technically incorrect since we dont know which 2 types it is\\n- PavedDrive: It could be argued that this variable should be numerically categorized rather than turned into dummy variables\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notes:\n",
    "- GarageType variable might be biased. Note that it has a 2types variable making our dummy variables technically incorrect since we dont know which 2 types it is\n",
    "- PavedDrive: It could be argued that this variable should be numerically categorized rather than turned into dummy variables\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET ENV VARIABLES\n",
    "train_csv = 'train.csv'\n",
    "test_csv = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2304c3003be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_project/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_project/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_project/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_project/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_project/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_project/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_project/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/train.csv'"
     ]
    }
   ],
   "source": [
    "# Read CSV\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "train_df_orig, test_df_orig = train_df, test_df\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the difference between columns in train_df and test_df\n",
    "test_df = test_df[set(train_df.columns).intersection(set(test_df.columns))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reviewing the housing dataset, we noticed several changes to existing features that would need to be preproccessed before being able to train a model.\n",
    "\n",
    "##### Integer/Float-based Variables\n",
    "Many features provided by the train dataset were in integer or float form. Many of these features provided the size (area) of rooms or the number of specific amenities like \"fireplaces\". These features being in numerical form allow us to keep most of them as its numerical value, only needing to normalize the values. There are some exceptions such as \"MSSubClass\" which, while having numerical values, should be treated as a categorical feature.\n",
    "\n",
    "##### Relative Categorical Variables\n",
    "The first type of feature that needed preprocessing was relative categroical values. Relative categorical variables are categorical variables that have some relation to each other. For example, the basement quality (\"bsmtQual\") feature has string values \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\", representing the overall qualtiy of the basement. While we could treat this like a normal categorical variable, creating a dummy variable for each category type, this strategy would not take into account that a \"Fa\" (Fair) rating is more similar to \"Po\" (Poor) than an \"Ex\" (Excellent) rating. As a result, we opted to replace these values to numerical values 1 through 5, to preserve the relationship between categories. \n",
    "\n",
    "##### Categorical Variables\n",
    "The second type of variable that needed preprocessing were normal categorical variables. After converting all the relative categrocial variables to integer values, we were able to automatically convert any other \"string\" or \"object\" type features in the dataset to dummy variables. Examples of the remaining categorical variables were \"Foundation\" and \"Heating\". For these remaining features, we converted each category into its own feature, giving the value a 1 if the sample was from that category and a 0 otherwise. This step increased the number of features in our dataset, though the number of unique categories for the remaining features is limited so this does not drastically affect the total number of features.\n",
    "\n",
    "##### Disproportionate Categorical Variables\n",
    "To minimize the number of unique features we create, we examined the categorical variables to see if we could find any trends. We found two categories, electrical and BsmtFinType2. We found that these categories were disprotionately \"SBrkr\" and \"Unf\" respectively. As a result, for these categories, we converted the feature to be 1 when its disproportionate category and 0 otherwise.\n",
    "\n",
    "##### Cyclical Variables\n",
    "We noticed that the Month Sold variable was a cyclical variable. While we could categorize each month into an integer, the model would assume that January and December are opposites, even though they are just one month apart. As a reuslt, we converted this feature into two features, the sine and cosine of the normalized value of the month. By doing so, we can use both features together to correctly model the relationship of months. This solution does have its limitations on models that consider only one feature at a time like Random Forest classifiers. This will be considered as we design our models.\n",
    "\n",
    "##### Missing Values\n",
    "Some features have NA values for some fields. We decided to resolve this issue with the by replacing NA values with  the average of all available values for that field in the training set. Assuming that the training and test set are  independent and identically distributed, using the same average for missing values in the test set should not lead to any issues. Unfortunately, using the average value for relative categorical variables (see above) is less than ideal since the average value does not necessarily give a good indiciation for the missing value. As a result, we add an extra feature for categorical variables that can be NA which is 1 of the value is NA and 0 if not, allowing the model to potentially learn to minimize the weight of the categorical variable when it is missing. \n",
    "\n",
    "\n",
    "##### Honorable Mentions\n",
    "Two variables stood out that could lead to issues or could lead to more preprocessing design decisions. First is the GarageType feature. This feature has a \"2types\" variable which occurs when the house has more than one garage type. The other categories for this feature represent the garage type. Since we convert this feature into dummy variables, having the 2type variable is an inaccuracy representation since in reality we would perfer to know which 2 types of garage the house has. This might lead to issues and will be kept in mind as we develop our models.\n",
    "Second, the PavedDrive feature contains three categories, paved, semipaved, and unpaved. One could argue that these are relative variables though in this preprocessing code we treated this as normal categorical variables. We might test both of these approaches with our models to see if we see different results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePreprocessor():\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        # Cnvrt disp Vars\n",
    "        self.disp_cats = [('Electrical', 'SBrkr'), ('BsmtFinType2', 'Unf')]\n",
    "        \n",
    "        # Cnvrt Relative Vars\n",
    "        rating_order_map = {\n",
    "            'Po': 0,\n",
    "            'Fa': 1,\n",
    "            'TA': 2,\n",
    "            'Gd': 3,\n",
    "            'Ex': 4,\n",
    "            'NA': 'NA',\n",
    "            np.nan: 'NA'\n",
    "        }\n",
    "\n",
    "        basement_exposure_map = {\n",
    "            'No': 0,\n",
    "            'Mn': 1,\n",
    "            'Av': 2,\n",
    "            'Gd': 3,\n",
    "            'NA': 'NA',\n",
    "            np.nan: 'NA'\n",
    "        }\n",
    "\n",
    "        basement_finish_map = {\n",
    "            'Unf': 0,\n",
    "            'LwQ': 1,\n",
    "            'Rec': 2,\n",
    "            'BLQ': 3,\n",
    "            'ALQ': 4,\n",
    "            'GLQ': 5,\n",
    "            'NA': 'NA',\n",
    "            np.nan: 'NA'\n",
    "        }\n",
    "\n",
    "        functional_rating = {\n",
    "            'Sal': 0,\n",
    "            'Sev': 1,\n",
    "            'Maj2': 2,\n",
    "            'Maj1': 3,\n",
    "            'Mod': 4,\n",
    "            'Min2': 5,\n",
    "            'Min1': 6,\n",
    "            'Typ': 7,\n",
    "            'NA': 'NA',\n",
    "            np.nan: 'NA'\n",
    "        }\n",
    "\n",
    "        garage_finish_rating = {\n",
    "            'Unf': 0,\n",
    "            'RFn': 1,\n",
    "            'Fin': 2,\n",
    "            'NA': 'NA',\n",
    "            np.nan: 'NA'\n",
    "        }\n",
    "\n",
    "        fence_quality_rating = {\n",
    "            \"MnWw\": 0,\n",
    "            \"GdWo\": 1,\n",
    "            \"MnPrv\": 2,\n",
    "            \"GdPrv\": 3,\n",
    "            \"NA\": \"NA\",\n",
    "            np.nan: 'NA'\n",
    "        }\n",
    "\n",
    "        bool_map = {\n",
    "            'N': 0,\n",
    "            'Y': 1\n",
    "        }\n",
    "\n",
    "        self.relative_categories = (\n",
    "            [(cat, rating_order_map) for cat in ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']] + \n",
    "            [(cat, basement_exposure_map) for cat in ['BsmtExposure']] +\n",
    "            [(cat, basement_finish_map) for cat in ['BsmtFinType1']] +\n",
    "            [(cat, functional_rating) for cat in ['Functional']] +\n",
    "            [(cat, garage_finish_rating) for cat in ['GarageFinish']] +\n",
    "            [(cat, fence_quality_rating) for cat in ['Fence']] +\n",
    "            [(cat, bool_map) for cat in ['CentralAir']]\n",
    "        )\n",
    "        \n",
    "        # Cyclical Vars\n",
    "        self.cyclical_features = ['MoSold']\n",
    "\n",
    "        # Dummy Vars\n",
    "        self.dummy_vars_to_append = ['MSSubClass']\n",
    "        \n",
    "    def process(self, df):\n",
    "        df = self.__cnvrt_disp_class_vars__(df)\n",
    "        df = self.__cnvrt_relative_cats__(df)\n",
    "        df = self.__cnvrt_cyclical_vars__(df)\n",
    "        \n",
    "        self.__log_remaining_category_vars__(df)\n",
    "        \n",
    "        df =  self.__add_dummy_vars__(df)\n",
    "        \n",
    "        df = self.__cnvrt_na_to_avg__(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def __cnvrt_disp_class_vars__(self, df):\n",
    "        # Convert Disproportionate Classification Variables\n",
    "        \"\"\"\n",
    "        NOTE: The electrical variable is disproportionately SBrkr. As a result, we will convert Electrical to a boolean of SBrkr vs Not SBrkr rather than creating more variables\n",
    "\n",
    "        SBrkr - 1334 (91.5%)\n",
    "        FuseA - 1    (0.05%)\n",
    "        FuseF - 94   (6.5%)\n",
    "        FuseP - 27   (1.8%)\n",
    "        Mix   - 3    (0.25%)\n",
    "\n",
    "        NOTE: The electrical variable is disproportionately SBrkr. As a result, we will convert Electrical to a boolean of SBrkr vs Not SBrkr rather than creating more variables\n",
    "\n",
    "        GLQ - 14\n",
    "        ALQ - 19\n",
    "        BLQ - 33\n",
    "        Rec - 54\n",
    "        LwQ - 46\n",
    "        Unf - 1256\n",
    "        NA - 38\n",
    "\n",
    "\n",
    "        Note: An argument could be made to do the same for BsmtExposure, though we have decided against converting it into a boolean variable\n",
    "\n",
    "        GD - 134\n",
    "        Av - 221\n",
    "        Mn - 114\n",
    "        No - 953\n",
    "        NA - 38\n",
    "\n",
    "        \"\"\"       \n",
    "        for cat, key in self.disp_cats:\n",
    "            df[cat] = [1 if e == key else 0 for e in df[cat]]\n",
    "            \n",
    "        return df\n",
    "            \n",
    "    def __cnvrt_relative_cats__(self, df):\n",
    "        # Convert Relative Categorical into numerical\n",
    "        for cat, map in self.relative_categories:\n",
    "            num_na = len([i for i in df[cat] if i is np.nan])\n",
    "            df[cat] = [map[rating] for rating in df[cat]]\n",
    "            cat_na = f'{cat}_NA'\n",
    "\n",
    "            # Create Boolean NA Column\n",
    "            df[cat_na] = [1 if v == 'NA' else 0 for v in df[cat]]\n",
    "\n",
    "            assert(num_na == sum(df[cat_na]))\n",
    "\n",
    "            # Convert NA to average (IS THIS REALLY THE BEST STRATEGY?)\n",
    "            avg = np.average([i for i in df[cat] if i != 'NA'])\n",
    "            df[cat] = [i if i != 'NA' else avg for i in df[cat]]\n",
    "        return df\n",
    "            \n",
    "    def __cnvrt_cyclical_vars__(self, df):\n",
    "        # Convert to cyclical (See for more information)\n",
    "        for f in self.cyclical_features:\n",
    "            norm = 2 * math.pi * df[f] / df[f].max()\n",
    "            df[f'{f}_sin'] = np.sin(norm)\n",
    "            df[f'{f}_cos'] = np.cos(norm)\n",
    "            df.drop(f, 1)\n",
    "            \n",
    "        return df\n",
    "            \n",
    "    def __log_remaining_category_vars__(self, df):\n",
    "        if self.verbose:\n",
    "            # Decide which categorical variables you want to use\n",
    "            # TODO: Convert to bar chart\n",
    "            for col_name in df.columns:\n",
    "                if df[col_name].dtypes == 'object':\n",
    "                    unique_cat = len(df[col_name].unique())\n",
    "                    print(f'Feature {col_name} has {unique_cat} unique categories')\n",
    "            \n",
    "    def __add_dummy_vars__(self, df):           \n",
    "        dummy_list = [col for col in df.columns if df[col].dtypes == 'object']\n",
    "        dummy_list = dummy_list + self.dummy_vars_to_append\n",
    "        \n",
    "        for cat in dummy_list:\n",
    "            dummies = pd.get_dummies(df[cat], prefix=cat, dummy_na=True)\n",
    "            df = df.drop(cat, 1)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def __cnvrt_na_to_avg__(self, df):\n",
    "        # NOTE: Since Garage YR blt has NA values, we have decided to deal with this by using the average year as the NA value \n",
    "        # (IS THIS REALLY THE BEST STRATEGY?)\n",
    "        cols_with_na = df.isnull().sum().sort_values(ascending=False)\n",
    "        cols_with_na = list(cols_with_na[cols_with_na > 0].keys())\n",
    "        \n",
    "        for col in cols_with_na:\n",
    "            if self.verbose:\n",
    "                print(f\"Converting nan's in {col} to avg of {col}\")\n",
    "            \n",
    "            avg = np.average([i for i in df[col] if not np.isnan(i)])\n",
    "            df[col] = [avg if np.isnan(i) else i for i in df[col]]\n",
    "        \n",
    "        cols_with_na = df.isnull().sum().sort_values(ascending=False)\n",
    "        cols_with_na = cols_with_na[cols_with_na > 0]\n",
    "        assert 0 == cols_with_na.shape[0]\n",
    "        \n",
    "        return df       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HousePreprocessor()\n",
    "train_df = hp.process(train_df)\n",
    "print(\"-------------------------\")\n",
    "test_df = hp.process(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# # Normalize Features\n",
    "# train_vals = train_df.values\n",
    "# test_vals = test_df.values\n",
    "\n",
    "# train_ids = train_df['Id']\n",
    "# test_ids = test_df['Id']\n",
    "\n",
    "# min_max_scaler_train = preprocessing.MinMaxScaler()\n",
    "# min_max_scaler_test = preprocessing.MinMaxScaler()\n",
    "# train_scaled = min_max_scaler_train.fit_transform(train_vals)\n",
    "# test_scaled = min_max_scaler_test.fit_transform(test_vals)\n",
    "# train_df = pd.DataFrame(train_scaled,  columns=train_df.columns, index=train_df.index)\n",
    "# test_df = pd.DataFrame(test_scaled,  columns=test_df.columns, index=test_df.index)\n",
    "# train_df['Id'] = train_ids\n",
    "# test_df['Id'] = test_ids\n",
    "\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=train_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SalePrice'].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SalePrice'].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_orig['MoSold'].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
